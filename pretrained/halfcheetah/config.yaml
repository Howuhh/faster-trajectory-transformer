wandb:
  project: faster_trajectory_transformer
  name: halfcheetah_medium
  group: gpt_cache
  entity: Howuhh
  mode: offline
dataset:
  env_name: halfcheetah-medium-v2
  seq_len: 10
  cache_path: data
  num_bins: 100
  discount: 0.99
  strategy: uniform
  batch_size: 256
model:
  vocab_size: 100
  transition_dim: 25
  observation_dim: 17
  action_dim: 6
  seq_len: 250
  embedding_dim: 128
  num_layers: 4
  num_heads: 4
  use_sep_heads: true
trainer:
  num_epochs_ref: 50
  action_weight: 5
  value_weight: 1
  reward_weight: 1
  lr: 0.0006
  betas:
  - 0.9
  - 0.95
  weight_decay: 0.1
  clip_grad: 1.0
  eval_seed: 42
  eval_every: 10
  eval_episodes: 5
  eval_discount: 0.99
  eval_temperature: 1
  eval_plan_every: 1
  eval_beam_width: 32
  eval_beam_steps: 5
  eval_beam_context: 5
  eval_sample_expand: 2
  eval_k_obs: 1
  eval_k_reward: 1
  eval_k_act: null
  checkpoints_path: checkpoints/halfcheetah-medium-v2/uniform/baseline
run_seed: 42
